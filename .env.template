# DSPy Zero-to-Expert Environment Configuration
# Copy this file to .env and fill in your API keys

# =============================================================================
# LLM Provider API Keys
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Cohere Configuration
COHERE_API_KEY=your_cohere_api_key_here

# =============================================================================
# Search and Tool APIs
# =============================================================================

# Tavily Search API
TAVILY_API_KEY=your_tavily_api_key_here

# =============================================================================
# Observability and Monitoring
# =============================================================================

# Langfuse Configuration
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here
LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here
LANGFUSE_HOST=https://cloud.langfuse.com  # or your self-hosted instance

# MLflow Configuration
MLFLOW_TRACKING_URI=http://localhost:5000  # or your MLflow server
MLFLOW_EXPERIMENT_NAME=dspy-learning

# =============================================================================
# Vector Database Configuration
# =============================================================================

# Qdrant Configuration
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your_qdrant_api_key_here  # Optional for local instance

# ChromaDB Configuration
CHROMA_HOST=localhost
CHROMA_PORT=8000

# =============================================================================
# Application Settings
# =============================================================================

# Environment
ENVIRONMENT=development  # development, staging, production

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=detailed  # simple, detailed, json

# Cache Settings
ENABLE_CACHE=true
CACHE_DIR=.cache
CACHE_TTL=3600  # seconds

# Model Defaults
DEFAULT_PROVIDER=openai
DEFAULT_MODEL=gpt-4.1

# Marimo Settings
MARIMO_HOST=localhost
MARIMO_PORT=2718
MARIMO_AUTO_RELOAD=true

# =============================================================================
# Development Settings
# =============================================================================

# Debug Mode
DEBUG=false

# Performance Monitoring
ENABLE_PROFILING=false
PROFILE_OUTPUT_DIR=profiles

# Testing
TEST_API_CALLS=false  # Set to true to make actual API calls during tests
TEST_TIMEOUT=30  # seconds